# transcribe-cli

In this directory are tools to perform transcription tasks from the command line (shell).

* `ms_recognize_pcm` a utility to perform speech recognition on an audio file using the Microsoft Azure-based Cognitive Services Speech-to-Text. This utility stores the results in a json file for future processing. 
* `ms_json_to_caption` a utility that can process the json file and create standard captioning files. Three formats are supported - "WebVTT" (`.vtt` extension), "SubRip" (`.srt` extension) caption files and plain text format (`.txt` extension).

# License & Acknowledgement

This project is "Acknowledgement-ware!" i.e. You are free to use the resources here subject to the open source licenses included in this repository and embedded in source files but we also request you publicly acknowledge us. An example acknowlegdgement is below.

"In ..<your-activity>.. we would like to acknowledge the use of ClassTranscribe (https://github.com/classtranscribe), a Digital Accessibility Project at the University of Illinois"

Academic papers and reports may also wish to cite ClassTranscribe related publications -

Chirantan, Angrave et al, '"What did I just miss?!" Presenting ClassTranscribe, an Automated Live- captioning and Text-searchable Lecture Video System, and Related Pedagogical Best Practices' Â© 2019 American Society for Engineering Education. ASEE Annual Conference Proceedings, 2019, Tampa Florida. [pdf](https://www.asee.org/public/conferences/140/papers/26836/download)

Ren, Jia Chen / Hasegawa-Johnson, Mark / Angrave, Lawrence (2015): "Classtranscribe: a new tool with new educational opportunities for student crowdsourced college lecture transcription", In SLaTE-2015, 179-180. [pdf](https://www.isca-speech.org/archive/slate_2015/papers/sl15_179.pdf)

# An important note on captioning

Captions generated by Automated Speech Recognition should be considered "first pass" to generate an initial draft. They will require additional manual editing to ensure they meet legal compliance standards and are usable for their intended purpose. For example an automated speech recognizer will make transcription errors, not describe sound effects and music and not identify the speaker. See <http://www.captioningkey.org/quality_captioning.html> for more information.

# Prequisites for Automated Speech Recognition

Some novice programming and shell / terminal skills are required. Summary -

* `Python 3` is required, together with the azure-cognitiveservices-speech SDK
* A Cognitive Services Azure API Key is required to use Speech-To-Text service
* `ffmpeg` is a useful utility to extract the 16Khz PCM audio suitable for automated speech recognition from a typical (e.g. 'mp4') video file 

Speech recognition is performed by sending audio to the Microsoft Cognitive Speech-to-text service.
To use the Microsoft Azure a Cognitive Services Azure API-Key and Azure account is required. The cost of transcription is approximately $1 per audio hour transcribed.

To connect to the Transcription service, you will need to install the python azure-cognitiveservices-speech SDK. A typical command to install the SDK is to use pip or pip3 -

```sh
pip3 install azure-cognitiveservices-speech
```

A web search of 'Microsoft python install azure-cognitiveservices-speech SDK' will find more detailed official instructions.

The `ms_recognize_pcm program` expects to find the api key and azure region as environment variables. On Mac OSX, Linux, and Microsoft Windows Subsystem for Linux, you can store these in a simple script (don't put spaces around the equals sign)-

```sh
> cat setenv.sh
export speech_key=12345your-key
export azure_region=westus
```

Then use `source setenv.sh` to set the environment variables before running `ms_recognize_pcm` 
For example, to recognize speech in the audio file myaudio.wav (that is in the required format 16KHz mono PCM) and to store the result in `recognizedspeech.json`

```sh
> source setenv.sh
> python3 ms_recognize_pcm.py myaudio.wav recognizedspeech.json
```

# Generating captions and transcriptions

The utility `ms_json_to_caption` works locally to convert the result of the automated speech recognition (saved by ` ms_recognize_pcm`) into a valid caption files.
Three output formats are supported - `WebVTT` (`.vtt` extension), `SubRip` (`.srt` extension) caption files and plain text format ('.txt' extension).

```sh
python3 ms_json_to_caption.py path-to-json-file output-file[s]
```

One or more output files can be specified. The output format is automatically for each file is inferred by the file extension (one of .vtt .srt or .txt).

For example, to generate all three output files just specify three output files -

```sh
python3 ms_json_to_caption.py recognizedspeech.json transcription.txt captions.vtt captions.srt
```
 
# Transcoding audio from video files

The audio file must be 16KHz mono (single channel) PCM format. One method to extract or transcode the audio into the correct format is to use `ffmpeg`. An example shell command is shown below. The `ffmpeg` command can also transcode audio from other formats (e.g. mp3) into the correct format for speech recognition. Please see the official ffmpeg documentation for further details.

```sh
ffmpeg -y -i video-source.mp4 -acodec pcm_s16le -f s16le -ac 1 -ar 16000 audio-output.wav
```

# Embedding captions into mp4 video files

The ffmpeg utility can be used to embed srt formatted closed captions into mp4 video files. An example is shown below that will work with a typical mp4 video file with a standard mpeg container. This example takes video-source.mp4 as input mycaptions.srt and creates a new output video file 'video-with-captions.mp4' with the captions embedded inside the video file. Most mp4 mpeg containers can support captions and even multiple captions for different multiple languages. Please see the official ffmpeg documentation for further information.

```sh
ffmpeg -i video-source.mp4 -i mycaptions.srt -c:v copy -c:a copy -c:s mov_text video-with-captions.mp4
```
